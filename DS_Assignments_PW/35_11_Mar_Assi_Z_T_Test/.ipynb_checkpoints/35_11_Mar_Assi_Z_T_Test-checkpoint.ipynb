{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Masters - Hindi - 11 Mar 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. What is the difference between a t-test and a z-test? Provide an example scenario where we would use each type of test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both t-test and z-test are used to test hypotheses about population means.\n",
    "    - However, there are certain differences between these two tests in terms of their assumptions, application, and usage.\n",
    "#\n",
    "- The main difference between the two tests is that the t-test is used when the sample size is small (n < 30) or the population standard deviation is unknown.\n",
    "- The z-test is used when the sample size is large (n ≥ 30) and the population standard deviation is known or can be estimated.\n",
    "#\n",
    "An example scenario where we would use a t-test is when we want to compare the means of two small samples (n < 30).\n",
    "    - We might want to compare the average scores of two groups of students who took different versions of the same test.\n",
    "        - We could use a t-test to determine if there is a statistically significant difference between the means of the two groups.\n",
    "#\n",
    "- Another example scenario where we would use a z-test is when we want to compare the means of two large samples (n ≥ 30).\n",
    "    - We might want to compare the average income of two different cities. we could use a z-test to determine if there is a statistically significant difference between the means of the two cities.\n",
    "#\n",
    "- It's worth noting that the z-test is considered more powerful than the t-test when the sample size is large.\n",
    "- The z-test assumes a normal distribution and is based on a known population standard deviation, whereas the t-test assumes a t-distribution and is based on an estimated standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Differentiate between one-tailed and two-tailed tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One-tailed and two-tailed tests are two types of hypothesis tests that are used in statistical analysis.\n",
    "#|\n",
    "- The main difference between them is the directionality of the alternative hypothesis.\n",
    "#\n",
    "- One-tailed test\n",
    "    - The alternative hypothesis is directional, meaning it specifies either an increase or a decrease in the population parameter being tested.\n",
    "    - This means that the test is looking for evidence of an effect in only one direction.\n",
    "        - For example, if we were testing the hypothesis that a new drug improves a medical condition, a one-tailed test would be appropriate if we only want to know if the drug has a positive effect (increases the proportion of patients who recover) and not if it has a negative effect (decreases the proportion of patients who recover).\n",
    "#\n",
    "- Two-tailed test\n",
    "    - The alternative hypothesis is non-directional, meaning it specifies that the population parameter is different from the null hypothesis, but does not specify the direction of the difference.\n",
    "    - This means that the test is looking for evidence of an effect in either direction.\n",
    "        - For example, if we were testing the hypothesis that a coin is fair (equal probability of heads and tails), a two-tailed test would be appropriate since we are interested in whether the coin is biased towards either heads or tails.\n",
    "#\n",
    "- The choice between a one-tailed and two-tailed test depends on the research question and the directionality of the hypothesis.\n",
    "- If the hypothesis specifies a particular direction, a one-tailed test may be appropriate. However, if the hypothesis does not specify a particular direction, or if both directions are of interest, a two-tailed test may be more appropriate.\n",
    "- It's important to note that a one-tailed test is generally more powerful than a two-tailed test, since it is focused on one direction of effect, but it also carries a higher risk of type I error if the direction of the effect is mis-specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. Explain the concept of Type 1 and Type 2 errors in hypothesis testing. Provide an example scenario for each type of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Type 1 and Type 2 errors are two types of errors that can occur in hypothesis testing when we reject or fail to reject a null hypothesis.\n",
    "#\n",
    "- Type 1 error\n",
    "    - It is also known as a false positive.\n",
    "    - It occurs when we reject a true null hypothesis.\n",
    "    - We conclude that there is a significant effect when in fact there is no effect.\n",
    "    - The probability of making a Type 1 error is denoted by alpha (α) and is set as the level of significance for the test.\n",
    "    - A commonly used level of significance is 0.05 (or 5%).\n",
    "    #\n",
    "    - Example\n",
    "        - A company tests a new product and concludes that it increases sales, based on a statistical analysis with a significance level of 0.05.\n",
    "            - However, in reality, the product has no effect on sales.\n",
    "            - This is a Type 1 error.\n",
    "#\n",
    "- Type 2 error\n",
    "    - It is also known as a false negative.\n",
    "    - It occurs when we fail to reject a false null hypothesis.\n",
    "    - We conclude that there is no significant effect when in fact there is an effect.\n",
    "    - The probability of making a Type 2 error is denoted by beta (β) and is influenced by factors such as the sample size, effect size, and level of significance.\n",
    "    #\n",
    "    - Example\n",
    "        - A medical test is designed to detect a disease, but it fails to detect the disease in a patient who actually has the disease.\n",
    "            - This is a Type 2 error.\n",
    "#\n",
    "- In hypothesis testing, we aim to minimize both Type 1 and Type 2 errors, but there is often a trade-off between the two. Lowering the level of significance (α) will reduce the risk of Type 1 error but increase the risk of Type 2 error, while increasing the sample size or the effect size will reduce the risk of Type 2 error but may increase the risk of Type 1 error.\n",
    "- It's important to choose the appropriate level of significance and sample size based on the research question and the consequences of making each type of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4. Explain Bayes's theorem with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The theorem is named after Reverend Thomas Bayes, an 18th-century British statistician.\n",
    "- Bayes's theorem is a mathematical formula that describes the relationship between conditional probabilities.\n",
    "- It allows us to update our prior beliefs about the probability of an event, based on new evidence or information.\n",
    "#\n",
    "- Bayes's theorem states that the probability of an event A, given the occurrence of an event B, is equal to the probability of event B given event A, multiplied by the prior probability of event A, divided by the prior probability of event B. Mathematically, it can be expressed as:\n",
    "    - P(A|B) = P(B|A) * P(A) / P(B)\n",
    "        - where:\n",
    "            - P(A|B) is the conditional probability of A given B\n",
    "            - P(B|A) is the conditional probability of B given A\n",
    "            - P(A) is the prior probability of A\n",
    "            - P(B) is the prior probability of B\n",
    "            #\n",
    "- Example\n",
    "    - A medical test for a rare disease. Let's say the disease affects 1% of the population, and the test is 99% accurate (meaning it correctly identifies 99% of those with the disease and 99% of those without the disease).\n",
    "        - If a person tests positive for the disease, what is the probability that they actually have the disease?\n",
    "    #\n",
    "    Solution:\n",
    "    #\n",
    "    - We can use Bayes's theorem to calculate this probability as follows:\n",
    "        - Let A = the event of having the disease\n",
    "        - Let B = the event of testing positive for the disease\n",
    "        - P(A) = 0.01 (the prior probability of having the disease)\n",
    "        - P(B|A) = 0.99 (the probability of testing positive given that he have the disease)\n",
    "        - P(B|not A) = 0.01 (the probability of testing positive given that he does not have the disease)\n",
    "        - P(not A) = 0.99 (the prior probability of not having the disease)\n",
    "    #\n",
    "    - Using these values, we can calculate the conditional probability of having the disease given a positive test result:\n",
    "        - P(A|B) = P(B|A) * P(A) / P(B)\n",
    "        - P(A|B) = 0.99 * 0.01 / ((0.99 * 0.01) + (0.01 * 0.99))\n",
    "        - P(A|B) = 0.50\n",
    "    #\n",
    "- This means that the probability of actually having the disease, given a positive test result, is only 50%, despite the high accuracy of the test.\n",
    "- This highlights the importance of understanding the context and prior probabilities when interpreting the results of any statistical analysis or hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. What is a confidence interval? How to calculate the confidence interval, explain with an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A confidence interval is a range of values that is likely to contain the true value of a population parameter, such as a mean or a proportion, with a certain level of confidence.\n",
    "- It is an estimation technique used in statistics to express the uncertainty associated with a sample statistic. In other words, a confidence interval is a range of values that we are reasonably sure that the true population parameter lies within.\n",
    "#\n",
    "- The calculation of a confidence interval involves selecting a sample from a population, calculating a statistic (such as a mean or proportion) from the sample, and then constructing an interval around the statistic that accounts for the sampling variability.\n",
    "- The interval is constructed in such a way that it is likely to contain the true population parameter a certain percentage of the time, which is determined by the level of confidence.\n",
    "#\n",
    "- To calculate a confidence interval, we need to determine three things\n",
    "    - The sample statistic\n",
    "    - The level of confidence\n",
    "    - The margin of error\n",
    "        - The margin of error is the amount by which the sample statistic might differ from the true population parameter.\n",
    "#\n",
    "- Example\n",
    "    - Let's say we want to estimate the average height of students in a university. We randomly select a sample of 100 students and measure their height. The sample mean height is 68 inches and the sample standard deviation is 3 inches. We want to construct a 95% confidence interval for the true population mean height.\n",
    "    #\n",
    "    - Solution\n",
    "    #\n",
    "    - To calculate the confidence interval, we can use the following formula:\n",
    "        - Confidence interval = sample mean +/- margin of error\n",
    "            - where,\n",
    "                - the margin of error is equal to the critical value multiplied by the standard error.\n",
    "                #\n",
    "    - The critical value is determined based on the level of confidence and the degrees of freedom (n-1).\n",
    "    - For a 95% confidence interval with 99 degrees of freedom, the critical value is 1.984.\n",
    "    - The standard error is equal to the sample standard deviation divided by the square root of the sample size.\n",
    "        - std = 3 / sqrt(100) = 0.3.\n",
    "        - Plugging these values into the formula, we get:\n",
    "    - Confidence interval = 68 +/- (1.984 * 0.3)\n",
    "    - Confidence  = 68 +/- 0.5952\n",
    "    - Confidence interval = (67.4048, 68.5952)\n",
    "    #\n",
    "    - So, we can say with 95% confidence that the true population mean height lies within the interval of 67.4048 inches to 68.5952 inches.\n",
    "    - This means that if we repeated the process of selecting a sample and constructing a confidence interval many times, 95% of the resulting intervals would contain the true population mean height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6. Use Bayes' Theorem to calculate the probability of an event occurring given prior knowledge of the event's probability and new evidence. Provide a sample problem and solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bayes' theorem is a mathematical formula that calculates the probability of an event occurring given prior knowledge of the event's probability and new evidence. The formula is as follows:\n",
    "    - P(A|B) = P(B|A) x P(A) / P(B)\n",
    "        - Where:\n",
    "            - P(A|B) is the probability of A given B (the probability of the event occurring given the new evidence)\n",
    "            - P(B|A) is the probability of B given A (the probability of the new evidence given the event occurring)\n",
    "            - P(A) is the prior probability of A (the probability of the event occurring before any new evidence is considered)\n",
    "            - P(B) is the probability of B (the probability of the new evidence occurring)\n",
    "Here is a sample problem to illustrate how Bayes' theorem works:\n",
    "#\n",
    "- Sample Problem\n",
    "    - In a certain city, 10% of people are left-handed. A study was conducted on a group of 100 people and it was found that 15% of them were left-handed. What is the probability that a randomly selected person from this city is left-handed given this new evidence?\n",
    "    #\n",
    "    - Solution:\n",
    "    #\n",
    "    - First, we need to identify the probabilities given in the problem:\n",
    "    - P(A) = 0.1 (the prior probability of being left-handed)\n",
    "    - P(B|A) = 0.15 (the probability of the new evidence, which is being left-handed according to the study, given that a person is left-handed)\n",
    "    - P(B|not A) = 0.85 (the probability of the new evidence, which is being left-handed according to the study, given that a person is not left-handed)\n",
    "    #\n",
    "    Note: P(B|not A) is equal to 1 - P(B|A), since the probabilities of being left-handed and not being left-handed add up to 1.\n",
    "    #\n",
    "    - We can now calculate P(B), the probability of the new evidence occurring, by using the law of total probability:\n",
    "    - P(B) = P(B|A) x P(A) + P(B|not A) x P(not A)\n",
    "    - = 0.15 x 0.1 + 0.85 x 0.9\n",
    "    - = 0.165\n",
    "        - Where P(not A) = 1 - P(A) = 0.9 is the probability of not being left-handed.\n",
    "\n",
    "    - Now we can use Bayes' theorem to calculate P(A|B), the probability of being left-handed given the new evidence:\n",
    "    - P(A|B) = P(B|A) x P(A) / P(B)\n",
    "    - = 0.15 x 0.1 / 0.165\n",
    "    - = 0.0909 (rounded to four decimal places)\n",
    "\n",
    "    - Therefore, the probability that a randomly selected person from this city is left-handed given the new evidence is approximately 0.0909 or 9.09%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7. Calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5. Interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5, we need to use the formula:\n",
    "\n",
    "CI = x̄ ± z * (σ/√n)\n",
    "\n",
    "Where:\n",
    "\n",
    "x̄ is the sample mean (50 in this case)\n",
    "σ is the population standard deviation (we use the sample standard deviation as an estimate when it is unknown)\n",
    "n is the sample size\n",
    "z is the z-score associated with the desired level of confidence (in this case, 95% corresponds to a z-score of 1.96)\n",
    "Plugging in the values, we get:\n",
    "\n",
    "CI = 50 ± 1.96 * (5/√n)\n",
    "\n",
    "To calculate the confidence interval, we need to know the sample size (n). Let's assume that the sample size is 100:\n",
    "\n",
    "CI = 50 ± 1.96 * (5/√100)\n",
    "= 50 ± 0.98\n",
    "\n",
    "The 95% confidence interval for this sample of data is (49.02, 50.98).\n",
    "\n",
    "Interpretation: We are 95% confident that the true population mean falls within the range of 49.02 to 50.98. In other words, if we were to take many samples of the same size from the same population and calculate a 95% confidence interval for each sample, approximately 95% of those intervals would contain the true population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8. What is the margin of error in a confidence interval? How does sample size affect the margin of error? Provide an example of a scenario where a larger sample size would result in a smaller margin of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The margin of error is a measure of the precision of an estimate or the uncertainty of a statistic. In the context of confidence intervals, it is the amount added and subtracted to the point estimate to create the interval that will contain the true population parameter with a certain level of confidence.\n",
    "\n",
    "The margin of error is determined by the sample size, the standard deviation of the population, and the desired level of confidence. As the sample size increases, the margin of error decreases, meaning the estimate becomes more precise.\n",
    "\n",
    "A larger sample size results in a smaller margin of error because it reduces the variability in the data and produces a more representative sample of the population. For example, suppose we want to estimate the proportion of students at a university who support a particular candidate in a student government election. If we randomly survey 50 students and find that 60% of them support the candidate, the point estimate is 0.6. If we construct a 95% confidence interval using a sample size of 50, the margin of error is approximately 12.3%:\n",
    "\n",
    "CI = 0.6 ± 1.96 * √(0.6 * 0.4 / 50)\n",
    "= (0.477, 0.723)\n",
    "\n",
    "However, if we increase the sample size to 500, the margin of error decreases to approximately 3.1%:\n",
    "\n",
    "CI = 0.6 ± 1.96 * √(0.6 * 0.4 / 500)\n",
    "= (0.569, 0.631)\n",
    "\n",
    "Therefore, a larger sample size would result in a smaller margin of error and a more precise estimate of the proportion of students who support the candidate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
